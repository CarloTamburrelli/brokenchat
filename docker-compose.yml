version: '3.8'
services:

  postgres:
    image: postgres:13
    container_name: postgres_chat
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: your_password
      POSTGRES_DB: chat_db
    ports:
      - 5432:5432
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - chat-net

  redis:
    image: redis:latest
    container_name: redis_chat
    ports:
      - 6379:6379
    networks:
      - chat-net

  backend:
    build: ./backend
    env_file:
      - ./backend/.env
    container_name: node_backend
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: postgres
      DB_PASSWORD: your_password
      DB_NAME: chat_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
    volumes:
      - ./backend:/app
    ports:
      - 5002:5002
    depends_on:
      - postgres
      - redis
    networks:
      - chat-net
  llama:
    image: ghcr.io/ggml-org/llama.cpp:server
    container_name: llama
    ports:
      - "8000:8080"
    volumes:
      - ./models:/models
    command: ["-m", "/models/tinyllama.gguf", "-t", "4", "-c", "1024"]
    restart: unless-stopped

volumes:
  postgres_data:

networks:
  chat-net:
    driver: bridge
